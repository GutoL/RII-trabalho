{
    "paper_authors_list": [
        "Yu, Ronald", 
        "Saito, Shunsuke", 
        "Li, Haoxiang", 
        "Ceylan, Duygu", 
        "Li, Hao"
    ], 
    "paper_comments": "To appear in ICCV 2017", 
    "paper_page_url": "https://arxiv.org/abs/1709.00536", 
    "paper_abstract": "We present a minimalistic but effective neural network that computes dense\nfacial correspondences in highly unconstrained RGB images. Our network learns a\nper-pixel flow and a matchability mask between 2D input photographs of a person\nand the projection of a textured 3D face model. To train such a network, we\ngenerate a massive dataset of synthetic faces with dense labels using\nrenderings of a morphable face model with variations in pose, expressions,\nlighting, and occlusions. We found that a training refinement using real\nphotographs is required to drastically improve the ability to handle real\nimages. When combined with a facial detection and 3D face fitting step, we show\nthat our approach outperforms the state-of-the-art face alignment methods in\nterms of accuracy and speed. By directly estimating dense correspondences, we\ndo not rely on the full visibility of sparse facial landmarks and are not\nlimited to the model space of regression-based approaches. We also assess our\nmethod on video frames and demonstrate successful per-frame processing under\nextreme pose variations, occlusions, and lighting conditions. Compared to\nexisting 3D facial tracking techniques, our fitting does not rely on previous\nframes or frontal facial initialization and is robust to imperfect face\ndetections.", 
    "paper_subjects": null, 
    "paper_code": "1709.00536", 
    "paper_submission_date": "2017/09/02", 
    "paper_title": "Learning Dense Facial Correspondences in Unconstrained Images"
}