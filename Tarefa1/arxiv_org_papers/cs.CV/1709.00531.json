{
    "paper_authors_list": [
        "Wu, Yuhang", 
        "Kakadiaris, Ioannis A."
    ], 
    "paper_comments": "Accepted in International Joint Conference on Biometrics (IJCB) 2017", 
    "paper_page_url": "https://arxiv.org/abs/1709.00531", 
    "paper_abstract": "Registering a 3D facial model to a 2D image under occlusion is difficult.\nFirst, not all of the detected facial landmarks are accurate under occlusions.\nSecond, the number of reliable landmarks may not be enough to constrain the\nproblem. We propose a method to synthesize additional points (SensiblePoints)\nto create pose hypotheses. The visual clues extracted from the fiducial points,\nnon-fiducial points, and facial contour are jointly employed to verify the\nhypotheses. We define a reward function to measure whether the projected dense\n3D model is well-aligned with the confidence maps generated by two fully\nconvolutional networks, and use the function to train recurrent policy networks\nto move the SensiblePoints. The same reward function is employed in testing to\nselect the best hypothesis from a candidate pool of hypotheses. Experimentation\ndemonstrates that the proposed approach is very promising in solving the facial\nmodel registration problem under occlusion.", 
    "paper_subjects": null, 
    "paper_code": "1709.00531", 
    "paper_submission_date": "2017/09/02", 
    "paper_title": "Facial 3D Model Registration Under Occlusions With SensiblePoints-based Reinforced Hypothesis Refinement"
}