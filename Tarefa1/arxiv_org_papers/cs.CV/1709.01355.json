{
    "paper_authors_list": [
        "Cotter, Fergal", 
        "Kingsbury, Nick"
    ], 
    "paper_comments": "To Appear in the 27th IEEE International Workshop on Machine Learning For Signal Processing (MLSP) 2017. 6 pages, 3 figures", 
    "paper_page_url": "https://arxiv.org/abs/1709.01355", 
    "paper_abstract": "Scattering Transforms (or ScatterNets) introduced by Mallat are a promising\nstart into creating a well-defined feature extractor to use for pattern\nrecognition and image classification tasks. They are of particular interest due\nto their architectural similarity to Convolutional Neural Networks (CNNs),\nwhile requiring no parameter learning and still performing very well\n(particularly in constrained classification tasks).\n<br />In this paper we visualize what the deeper layers of a ScatterNet are\nsensitive to using a 'DeScatterNet'. We show that the higher orders of\nScatterNets are sensitive to complex, edge-like patterns (checker-boards and\nrippled edges). These complex patterns may be useful for texture\nclassification, but are quite dissimilar from the patterns visualized in second\nand third layers of Convolutional Neural Networks (CNNs) - the current state of\nthe art Image Classifiers. We propose that this may be the source of the\ncurrent gaps in performance between ScatterNets and CNNs (83% vs 93% on\nCIFAR-10 for ScatterNet+SVM vs ResNet). We then use these visualization tools\nto propose possible enhancements to the ScatterNet design, which show they have\nthe power to extract features more closely resembling CNNs, while still being\nwell-defined and having the invariance properties fundamental to ScatterNets.", 
    "paper_subjects": null, 
    "paper_code": "1709.01355", 
    "paper_submission_date": "2017/09/05", 
    "paper_title": "Visualizing and Improving Scattering Networks"
}