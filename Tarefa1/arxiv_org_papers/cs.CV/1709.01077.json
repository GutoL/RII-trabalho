{
    "paper_authors_list": [
        "Rosman, Guy", 
        "Fisher III, John W.", 
        "Rus, Daniela"
    ], 
    "paper_comments": null, 
    "paper_page_url": "https://arxiv.org/abs/1709.01077", 
    "paper_abstract": "Ego-centric data streams provide a unique opportunity to reason about joint\nbehavior by pooling data across individuals. This is especially evident in\nurban environments teeming with human activities, but which suffer from\nincomplete and noisy data. Collaborative human activities exhibit common\nspatial, temporal, and visual characteristics facilitating inference across\nindividuals from multiple sensory modalities as we explore in this paper from\nthe perspective of meetings. We propose a new Bayesian nonparametric model that\nenables us to efficiently pool video and GPS data towards collaborative\nactivities analysis from multiple individuals. We demonstrate the utility of\nthis model for inference tasks such as activity detection, classification, and\nsummarization. We further demonstrate how spatio-temporal structure embedded in\nour model enables better understanding of partial and noisy observations such\nas localization and face detections based on social interactions. We show\nresults on both synthetic experiments and a new dataset of egocentric video and\nnoisy GPS data from multiple individuals.", 
    "paper_subjects": null, 
    "paper_code": "1709.01077", 
    "paper_submission_date": "2017/09/04", 
    "paper_title": "A Nonparametric Model for Multimodal Collaborative Activities Summarization"
}